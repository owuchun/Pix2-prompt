---
name: pix2prompt
description: |
  Universal Visual Prompt Architect (Pix2Prompt). 
  Transforms ideas into professional prompts for BOTH Images (Midjourney/Flux/SD) and Videos (Sora/Seedance/Runway).
  Powered by Nano Banana Pro Style Library.
disable-model-invocation: false
---

# ğŸ¨ Pix2Prompt: Universal Visual Architect

**From Idea to Pixel-Perfect Prompt.**

This skill serves as your **Visual Director**, converting abstract ideas into high-precision technical prompts for any AI visual model.

**Core Capabilities:**
1.  **ğŸ–¼ï¸ Image Mode**: Generates prompts for Midjourney, Stable Diffusion, Flux, DALL-E.
2.  **ğŸ¬ Video Mode**: Generates cinematic storyboards for Sora, Seedance, Runway, Kling.
3.  **ğŸ¨ Style Engine**: Powered by **Nano Banana Pro Library** (6000+ Styles).

---

## ğŸ› ï¸ Usage Modes

### Mode 1: ğŸ–¼ï¸ Image Generation (Static)

**Goal**: Create stunning single-frame visuals.

**Language & Platform Rules**:

1.  **Response Language (Chat)**:
    - **ALWAYS match the User's Language** for the conversation part (explanation, style description).
    - If user speaks Chinese -> Explain in Chinese.
    - If user speaks English -> Explain in English.

2.  **Prompt Language (The Code Block)**:
    - **Chinese Models** (Doubao, Seed, Qwen/Tongyi Qianwen): **Chinese Prompt**.
    - **Global Models** (Nano Banana, Midjourney, Flux, SD, DALL-E): **English Prompt**.

**Workflow**:
1.  **Style Search**: Find specific visual styles from the Reference Library.
2.  **Parameter Tuning**: Apply model-specific parameters.
3.  **Prompt Output**:

    *   **Scenario A: User speaks Chinese + Global Model (e.g., "ç”ŸæˆMJæç¤ºè¯")**
        ```markdown
        **é£æ ¼åˆ†æ**: é€‰æ‹©äº†èµ›åšæœ‹å…‹é£æ ¼...
        **Prompt**: Cyberpunk city, neon lights... --ar 16:9
        ```

    *   **Scenario B: User speaks Chinese + Domestic Model (e.g., "ç”Ÿæˆè±†åŒ…æç¤ºè¯")**
        ```markdown
        **é£æ ¼åˆ†æ**: é€‰æ‹©äº†æ–°ä¸­å¼é£æ ¼...
        **æç¤ºè¯**: æ–°ä¸­å¼å›½æ½®ï¼Œä¸­å›½é¾™ï¼Œäº‘é›¾ç¼­ç»•...
        ```

    *   **Scenario C: User speaks English + Global Model**
        ```markdown
        **Style Analysis**: Selected Cyberpunk style...
        **Prompt**: Cyberpunk city, neon lights... --ar 16:9
        ```

### Mode 2: ğŸ¬ Video Storyboard (Dynamic)

**Goal**: Structure a compelling video narrative based on User Intent.

**Language Rule**:
- If user asks in Chinese, **Output the entire Storyboard in Chinese**.
- Use English only for specific technical terms.

**Step 1: Intent Recognition & Template Selection**
Agent must identify the video type and select the correct template:

*   **Type A: Narrative/Commercial (Default)**
    *   *Intent*: Telling a story, promoting a product, full music video.
    *   *Template*: Standard 5-Part Structure.
*   **Type B: Motion/Reference Clone**
    *   *Intent*: "Mimic this video", "Extend this clip", "Just copy camera move".
    *   *Template*: Simplified Reference Structure.

**Step 2: Generate Storyboard**

#### **Template A: Narrative/Commercial (æ ‡å‡†å™äº‹/å¹¿å‘Š)**
```text
ã€æ•´ä½“æè¿°ã€‘[é£æ ¼], [æ—¶é•¿], [ç”»å¹…], [æ°›å›´]

0-3ç§’: [è¿é•œæè¿°]ã€‚[ç”»é¢å†…å®¹æè¿°ï¼ŒåŒ…å«ä¸»ä½“å’Œç¯å¢ƒ]ã€‚
éŸ³æ•ˆ: [é…ä¹é£æ ¼] + [å…·ä½“éŸ³æ•ˆ]

3-7ç§’: [è¿é•œæè¿°]ã€‚[ç”»é¢å†…å®¹æè¿°]ã€‚
éŸ³æ•ˆ: [å…·ä½“éŸ³æ•ˆ]

7-11ç§’: [è¿é•œæè¿°]ã€‚[ç”»é¢å†…å®¹æè¿°]ã€‚
éŸ³æ•ˆ: [å…·ä½“éŸ³æ•ˆ]

11-13ç§’: [è¿é•œæè¿°]ã€‚[ç”»é¢å†…å®¹æè¿°]ã€‚
éŸ³æ•ˆ: [å…·ä½“éŸ³æ•ˆ]

13-15ç§’: [è¿é•œæè¿°]ã€‚[ç”»é¢å†…å®¹æè¿°]ã€‚
éŸ³æ•ˆ: [å…·ä½“éŸ³æ•ˆ]

ã€å‚è€ƒã€‘@å›¾ç‰‡1 ä½œä¸ºé¦–å¸§ï¼Œ@è§†é¢‘1 å‚è€ƒè¿é•œ (å¦‚æœ‰)
```

#### **Template B: Motion/Reference Clone (è¿é•œå¤åˆ»/å»¶é•¿)**
```markdown
ã€ä»»åŠ¡ã€‘[è§†é¢‘å»¶é•¿ / è¿é•œå¤åˆ» / é£æ ¼è¿ç§»]
ã€åŸºå‡†ç´ æã€‘@è§†é¢‘1 (ä¸»å‚è€ƒ)

ã€æç¤ºè¯ã€‘
å‚è€ƒ @è§†é¢‘1 çš„[è¿é•œ/åŠ¨ä½œ/ç‰¹æ•ˆ]ï¼Œå°†ä¸»ä½“æ›¿æ¢ä¸º @å›¾ç‰‡1ã€‚
[è¯¦ç»†æè¿°å¤åˆ»çš„åŠ¨ä½œç»†èŠ‚...]
(å¦‚æœæ˜¯å»¶é•¿) å»¶é•¿ 5ç§’ï¼Œæ–°å¢å†…å®¹ä¸ºï¼š[æè¿°]

ã€å‚æ•°è®¾ç½®ã€‘
- è¿åŠ¨å¹…åº¦ (Motion Bucket): [é«˜/ä½]
- é£æ ¼å¼ºåº¦: [Strong/Weak]
```

**Workflow**:
1.  **Style Search**: Define aesthetic tone (Nano Engine).
2.  **Intent Check**: Choose Template A or B.
3.  **Drafting**: Fill the template.

---

## ğŸ” Internal Logic (How it works)

### Step 1: Style Discovery (The "Nano" Engine)

**Smart Routing**: The skill uses **Category Signal Mapping** to search the most relevant JSON file first, ensuring high-quality style matches.

| User Request Signals | Target Category File |
|---------------------|----------------------|
| avatar, profile, headshot, selfie | `profile-avatar.json` |
| post, social media, viral, instagram | `social-media-post.json` |
| infographic, chart, data, edu | `infographic-edu-visual.json` |
| youtube, thumbnail, cover | `youtube-thumbnail.json` |
| comic, manga, storyboard, panel | `comic-storyboard.json` |
| product, ad, marketing, sale | `product-marketing.json` |
| game, asset, sprite, character | `game-asset.json` |
| poster, flyer, event, banner | `poster-flyer.json` |
| **Default / Unsure** | `others.json` |

*   **Search Logic**: `grep "keyword" references/[Category-File]`
*   **Fallback**: If no match in specific category, search `others.json`.

### Step 2: Prompt Synthesis & Multi-modal Input
It combines the **User's Subject** with the **Found Style**, **Technical Parameters**, and **Uploaded Materials**.

**Conflict Detection (Crucial)**:
Before generating, the Agent MUST check for style conflicts between the **Uploaded Image** and the **Requested Style**.
*   *Example Conflict*: User uploads a "Casual Cotton Hoodie" but asks for "Silk Embroidery / Traditional Ancient Style".
*   *Action*:
    1.  **Detect**: "Material Mismatch: Cotton vs Silk".
    2.  **Warn**: "Warning: Your image is casual streetwear, but the requested style is traditional ancient. This may look unnatural."
    3.  **Recommend**: Suggest a bridge style (e.g., "China-Chic Streetwear" instead of "Ancient Costume").

**Multi-modal Syntax (Video Mode)**:
Use strict referencing for user uploads to ensure consistency in Seedance/Sora.

*   `@Image[N]`: Reference image (N=1-9).
*   `@Video[N]`: Reference video for motion/camera.
*   **Syntax Examples**:
    *   `@Image1 as First Frame` (é¦–å¸§å‚è€ƒ)
    *   `@Image2 as Character Reference` (è§’è‰²å‚è€ƒ)
    *   `Reference @Video1 for Camera Movement` (è¿é•œå‚è€ƒ)

---

## ğŸ’¡ Prompt Templates

### For Midjourney / Image
> **[Subject]** in the style of **[Nano Style Name]**, **[Visual Adjectives]**, **[Lighting]**, **[Composition]**. --ar [Ratio] --stylize [Value]

### For Seedance / Video
> **[Overall Vibe]**: [Nano Style Keywords]
> **[Timeline]**:
> *   **0s**: [Camera] + [Subject Action]
> *   **End**: [Transition]

---

## ğŸ“‚ Reference Data
*   This skill relies on the **Nano Banana Pro** dataset located in the `references/` folder.
*   Ensure `references/*.json` files are present for full functionality.
